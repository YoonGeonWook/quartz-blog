---
sticker: emoji//1f525
tags:
  - Interpretability-Machine-Learning
---
ML 모델과 설명(explanations)을 분리하는 것, 즉 model-agnostic interpretation methods에는 몇 가지 장점이 있습니다. 우선은 유연성(flexibility) 입니다. 어떠한 해석 방법을 모든 모델에 적용할 수 있다면 ML 개발자는 모델을 더욱 자유롭게 사용할 수 있습니다. 시각화나 UI처럼 모델의 해석을 기반으로 만들어지는 것 역시 모델로부터 독립적입니다. 보통 하나의 작업을 해결할 때 하나가 아닌 여러 유형의 ML 모델을 평가하며, 해석 가능성 측면에서 모델을 비교할 때 model-agnostic explanations는 모든 유형의 모델에 동일한 방법을 사용할 수 있기 때문에 작업이 쉬워집니다. 

Model-agnostic 해석 방법에 대안은 오로지 interpretable model 만을 사용하는 것인데, 이는 다른 ML 모델에 비해 예측 성능이 떨어지고 한 가지 유형의 모델에 국한된다는 단점이 있습니다. 또 다른 대안은 model-specific 해석 방법을 사용하는 것입니다. 이 역시 한 가지 유형에 묶여 다른 유형으로 전환하기 어렵습니다. 

Model-agnostic 설명 시스템의 장점은 아래와 같습니다 : 

- **Model flexibility** : 모든 유형의 ML 모델에서 작동이 가능합니다
- **Explanation flexibility** : 특정한 형태의 설명 방식에 국한되지 않습니다. 어떤 경우에는 선형적인 형태가 유용하고, 또 어떤 경우에는 feature importance를 이용한 그래픽이 유용할 수 있습니다
- **Representation flexibility** : 설명 체계(explanation system)는 현재 설명하고자 하는 모델과는 다른 피쳐 표현 방식을 사용할 수 있어야 합니다. Abstract word embedding vectors 를 사용하는 text classifier는 개별 단어의 존재 여부를 설명에 사용하는 것이 더 바람직할 수 있습니다

#### The bigger picture

Model-agnostic Interpretability에 대해 대략적으로 살펴보겠습니다. 우리는 데이터를 수집하여 세상을 파악하고, ML 모델을 통해 필요한 데이터를 예측하는 학습을 함으로써 이를 더욱 단순화/추상화합니다. 해석 가능성은 인간이 이해하는 데 도움이 되는 도 다른 레이어에 불과합니다. 

![](Pasted%20image%2020240101195204.png) Figure 6.1 : Explainable ML의 big picture. 실제 세계는 여러 설명(explanations)들의 형태로 인간에게 전달되기까지 여러 레이어들을 거칩니다.

가장 아래의 레이어는 World 입니다. 이는 말 그대로 인체의 생물학이나 약물에 대한 반응과 같은 자연 그 자체일 수도 있고, 부동산 시장과 같은 보다 추상적인 것이기도 합니다. World 라는 레이어에는 관찰할 수 있고 관심 있는 모든 것이 포함됩니다. 궁극적으로 우리는 세상에서 무언가를 배우고 상호작용하기를 원합니다. 

두 번째 레이어는 데이터입니다. 컴퓨터에서 처리할 수 있고 정보를 저장하기 위해 World를 디지털화해야 합니다. 데이터 레이어에는 이미지, 텍스트, 표 형식의 데이터 모든 것이 포함됩니다. 

데이터 레이어를 기반으로 ML 모델을 fitting 하면 Black Box Model 레이어가 됩니다. ML 알고리즘은 현실 세계의 데이터로 학습하여 예측을 하거나 구조를 찾습니다. 

Black box model layer 위에는 ML 모델의 불투명성(opacity)을 다루는 데 도움이 되는 Interpretability Methods layer가 있습니다. 

마지막 layer가 바로 인간 Human 입니다. 인간은 결국 설명의 소비자입니다. 

이러한 다층적(multi-layered) 추상화(abstraction)는 통계학자 및 ML 실무자 간 접근 방식의 차이를 이해하는 데 도움이 됩니다. 통계학자는 임상시험을 계획하거나 설문조사를 설계하는 등 data layer를 다룹니다. 이들은 black box model layer를 건너뛰고 interpretability methods layer로 바로 이동합니다. ML 전문가도 이미지의 라벨링된 샘플을 수집하거나 위키피디아를 크롤링하는 등 data layer를 다룹니다. 그 다음 black box ML 모델을 훈련시킵니다. 이들은 interpretability methods layer를 건너뛰고 사람이 직접 black box model의 예측을 다룹니다. Interpretable ML 이 이러한 작업을 융합할 수 있다는 것입니다. 

Model-agnostic methods는 local method와 global method로 더 구분할 수 있습니다. Global methods는 평균적으로 예측에 어떤 영향을 미치는지를 설명하고, local methods는 개별 예측을 설명합니다. 

