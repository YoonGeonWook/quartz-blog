---
sticker: emoji//1f4d5
tags:
  - Anomaly_Detection
  - 이상탐지
banner: Anomaly Detection/image/overview.png
dg-publish: true
---
이상 탐지는 주어진 데이터를 기반으로 다른 패턴, 특징을 보이는 개체를 찾아내는 방법이다. Anomaly detection에 대한 설명을 하기 위해서 우선 고전적인 머신러닝의 개념부터 다시 한번 살펴보자.

## 🎯Machine Learning

명확히 정의된 task **<u>T</u>** 가 있고, 그 task에서 성능을 측정할 수 있는 방법 **<u>P</u>** 가 있을 때 경험(experience)/data **<u>E</u>** 를 (개선되는 방향으로) **<u>학습(learn)</u>** 하는 컴퓨터 프로그램을 Machine Learning; ML이라고 한다. 이 때 ML은 주어진 데이터에 따라 크게 두 가지로 분류할 수 있다. 

> [!failure|label] Supervised Learning
> - 데이터에 target 또는 outcome value $Y$ 가 주어진 경우
> - 주어진 $(X, Y)$ 를 통해 $X$와 $Y$ 간 관계(relationship)인 $Y=f(X)$를 알아내는 것이 목표
> - 분류(Classification), 회귀(Regression) 문제가 해당됨

<img src="C:\Users\USER\Desktop\STUDY\Anomaly Detection\assets\Overview\Pasted image 20240113174805.png"/>


> [!Note|label] Unsupervised Learning
> - 데이터에 $Y$가 주어지지 않은 경우
> - 데이터 $X$ 자체가 가지고 있는 내재적인 특징 $f(X)$ 를 알아내는 것이 목표
> - 데이터 $X$를 이용해 각 객체들의 밀도를 추정하거나, 군집을 찾거나 변수들 간 연관성을 유추함

![](assets/Overview/Pasted%20image%2020240113174821.png)

![](assets/Overview/Pasted%20image%2020240113174828.png)

## 🎯Anomaly Detection 

Abnormal/novel data에 대해 크게 두 가지 관점이 있다.

1. "Observations that deviate so much from other observations as to arounse suspicious that they were <font style="color:red">generated by a different mechanism</font> (Hawkins, 1980)"
	- 다른 보통의/일반적인 데이터와 다른 메커니즘으로 만들어진 데이터를 abnormal 이라고 한다
2. "Instances that their <font style="color:red">true probability density is very low</font> (Harmeling et al., 2006)"
	- 확률 밀도값이 매우 낮은 데이터를 abnormal 이라고 한다

이상 탐지에서 이상 데이터는 anomaly, novelty, outlier 로 사용되는 분야나 도메인에 따라 다르게 불린다. 여기서 novelty는 상대적으로 긍정적인 경우에 사용하는 명칭이다. 

#### Outliers vs. Noise data

데이터 분석 시 항상 주의해야 할 점은 Noise라는 용어와 이상 데이터를 잘 구분해야 한다. Noise는 데이터를 수집할 때 자연발생적으로 생긴 random error이다. 현실의 문제에선 이러한 noise는 항상 존재한다. 그 때문에 데이터에 내재된 noise의 존재를 갖어하고 모델을 구성해야 한다. 반면 outlier는 특이한 상황에서 발생하는, 일반적인 메커니즘과 다른 방식으로 만들어진 객체이다. 따라서 이는 반드시 찾아야하는 것으로, 이 객체를 찾는 것은 데이터의 특성을 분석하는 데 유용할 수 있다.

#### Classification vs. Anomaly Detection

Anomaly detection은 주어진 데이터가 normal 인지 abnormal인지를 구분해야 하기 때문에 목적 자체는 Supervised learning이다. 하지만 실제 동작 방식은 Unsupervised learning 이다. 그 이유는 정상 (normal)인 데이터만을 학습하기 때문이다. 이진 분류 문제의 경우와 비교해보자 : 

![](assets/Overview/Pasted%20image%2020240113180611.png)

위 그림에서, 주어진 데이터에서 normal은 <font style="color:blue">파란색 O</font>, abnormal은 <font style="color:red">빨간색 X</font>로 표시되어 있다. Binary classifiier는 주어진 데이터를 가지고 최적의 분류 경계면을 찾는다. 그렇기 때문에 새로운 데이터 A와 B는 이 경우엔 normal로 분류될 것이다. 

반면 anomaly detection 알고리즘은 주어진 데이터의 normal을 가지고 학습하기 때문에 normal 데이터 주위의 경계면을 만든다. 그렇기 때문에 anomaly detection 알고리즘은 <font style="color:red">빨간색 X</font>와 A, B 데이터들을 "정상이 아님"으로 판단한다. 이는 이들이 abnormal이라고 판단하는 것과 다르다. 일단 normal이 아니라는 것이고 그들에 대해 추가적인 분석을 해야 함을 나타내는 것이다. 

#### The way learning from data

- [x] Classification : 분류 알고리즘은 아래 그림과 같이 모델에게 사과와 바나나에 대한 이미지를 보여주고 학습시킨다. 

![](assets/Overview/Pasted%20image%2020240113181630.png)
- [x] Anomaly Detection : 이상 탐지 알고리즘은 normal data로만 학습한 boundary를 결정하는데, 여기서 문제는 boundary를 결정할 때 generalization과 specialization 간 trade-off가 발생한다는 것이다.

![](assets/Overview/20240115-1014-59.2161126.mp4)

따라서 Generalization(일반화)와 Specialization(구체화) 간 trade-off를 잘 조절하는 것이 중요한데, Genearlization에 더 치중할수록 실제로 abnormal data를 normal로 판단할 수 있고, Specailization에 가까울수록 normal data를 abnormal로 판단할 위험이 생기기 때문이다.

## 🎯Anomaly Detection Approach

#### Assumption
- [x] 이상 탐지 방법론에서 기본적으로 가정하는 것은 <font style="color:blue">normal</font> data가 <font style="color:red">abnormal</font> 보다 훨씬 많다는 것이다. 
아래 그림을 보면 분류 문제에서는 <font style="color:blue">normal</font>과 <font style="color:red">abnormal</font> data 모두를 가지고 classifier를 학습시킨다. 

![](assets/Overview/Pasted%20image%2020240115192140.png)
반면에 이상 탐지의 경우, <font style="color:red">novel/abnormal</font> data는 사용하지 않고 <font style="color:blue">normal</font> 
data 만을 가지고 detector를 학습시키는 것을 확인할 수 있다.

![](assets/Overview/Pasted%20image%2020240115192235.png)


그렇다면 Classification과 Anomaly Detection 중 어떤 것을 사용해야 할지에 대한 기준이 필요한데, 두 가지 고려사항이 있다 : 

![](assets/Overview/Pasted%20image%2020240115192445.png)

1) 우선은 주어진 데이터의 target 변수의 **class가 불균형한지 (imbalanced) 여부**를 확인해야 한다. 이 때 imbalnced 한 정도는 70:30 이 아닌 99:1 정도로 불균형한 정도가 심각한 경우를 말한다. 
2) Class imbalanced라고 판단되는 상황에서 **소수 집단 (minority)의 수가 굉장히 적을 경우**에 바로 Anomaly detection 알고리즘을 사용하면 좋다. 예를 들어, imbalanced 한 상황이지만 normal과 abnormal이 각각 999,000개, 1,000개 존재한다면 under/over sampling 기법을 활용하여 Classification 방식으로 접근할 수 있다. 하지만 normal과 abnormal이 9,990개, 10개 이렇게 있다고 하면 클래스 불균형을 해소할 수 없기 때문에 이상 탐지 기법으로 접근하는 것이 좋다. 

## 🎯Type of Abnormal Data

#### Global Outlier : 
- [x] Data set 대부분과 완전히 다른 객체를 말한다. 일반적으로 생각하는 outlier인 것이다. 

![](assets/Overview/Pasted%20image%2020240115193838.png)
#### Contextual/Local Outlier
- [x] 상황/맥락 (context)에 따라서 outlier일 수 있는 객체를 말한다. 
- [x] 예를 들어서 30℃인 객체는 사하라에서는 normal 이지만, 알래스카에서는 outlier가 된다. 
- [x] 유의미한 상황 (context)를 어떻게 정의하는지가 중요하다.

![](assets/Overview/Pasted%20image%2020240115194141.png)

#### Collective Outlier 
- [x] 객체 개별은 outlier가 아닐지라도, 집합적으로 또는 전체적으로 보았을 때 데이터의 대부분과 심하게 다를 경우 이를 collective outlier라고 한다. 
- [x] 예를 들어 Dos 공격에서 개별 client의 접속은 outlier가 아닐 수 있지만, 순간적으로 너무 많은  client들의 비정상적인 접속은 서버에 문제를 일으킬 것이므로 outlier라고 볼 수 있는 것이다. 

## 🎯Challenges

이상 탐지 모델링에서는 아래와 같이 해결해야 할 주요 문제 3가지가 있다. 

1) **Modeling normal objects and outliers properly** : 
	- 이상 탐지 알고리즘은 abnormal data가 충분히 확보되지 않은 상황, 심지어 오로지 normal data 만을 가지고 모델 학습을 진행해야 한다. 그렇기 때문에 해당 객체가 normal 인지 아닌지 결정하는 boundary를 정의하는 것이 매우 어렵고, 모호하다 - 이를 gray area 라고 부른다. 연속적인 데이터들에 대해서 이러한 경계(border)를 어떻게 결정할지 명확히 해야한다.
2) **Application-specific outlier detection** : 
	- 이상 탐지가 사용되는 분야 (domain)에 따라서 모델이 사용하는 거리 측정 방식 (distance measure)이나 outlier 판정 cut-off가 다르다. 
	- 예를 들어서 의료 데이터 분석에서는 굉장히 작은 편차를 갖는 객체도 outlier일 수 있고, 반면에 마케팅 분석에서는 상당한 편차를 가져야 outlier로 볼 수 있다. 
3) **Understandability** : 
	- 이상 탐지 모델이 특정 객체(들)를 outlier로 판단한 이유를 말할 수 있어야 한다. 
	- 그렇기 때문에 outlier인 정도(degree)를 명시하기 위해서 normal mechanism에서 그러한 outlier가 생성될 **abnormal score**를 계산하는 것이다. 

## 🎯Performance Measures

Anomaly detection은 학습 과정은 unsupervised learning과 비슷하나, 성능은 unseed data인 test set으로 평가하기 때문에 supervised learning의 목적을 가지고 있다고 했다. 그렇기 때문에 test set에 대한 모델의 성능을 측정하기 위해서 confusion matrix를 이용할 수 있다.

허나 이러한 confunsion matrix는 abnormal scores에 대한 cut-off (threshold)가 지정된 이후에 사용이 가능하다.

- [x] Confusion matrix for novelty detection : 

![](assets/Overview/Pasted%20image%2020240115195747.png)
- [x] Performance measures : 

![](assets/Overview/Pasted%20image%2020240115195918.png)
- Detection rate : 실제로 abnormal인 것 중에서 모델이 abnormal이라고 판별한 비율
	- 일반적인 분류 문제에서 민감도 (sensitivity) 또는 재현율 (recall)과 같다.
- FRR : 실제로는 normal이지만 모델이 abnormal이라고 잘못 판별한 비율이다.
- FAR : 실제로는 abnormal이지만 모델이 normal이라고 잘못 판별한 비율이다. 

 여기서 FRR과 FAR은 반비례의 관계에 있다. 어떤 모델이 상대적으로 abnormal로 더 많이 판별해 낸다고 하면 FRR 값은 큰데 비해 FAR은 작을 것이기 때문이다. 

앞서 anomaly detection의 challenges 부분에서 언급한 것처럼 normal과 abnormal을 판별하는 boundary를 정의하기 위한 cut-off를 지정하는 것이 어렵다. 그렇기 때문에 이러한 boundary cut-off 값을 바꿔가면서 confusion matrix 및 performance measures를 계산해야 한다. 그렇게 하면 아래와 같은 FRR-FAR curve를 그릴 수 있다.

![](assets/Overview/Pasted%20image%2020240115201202.png)
- 여러가지 cut-off 값에 따라서 그려진 FRR-FAR plot에서 y=x 직선과의 교점을 **Equal Error Rate (ERR)** 이라고 한다. 이 값은 작을수록 더 좋은 성능을 낸다고 판단한다.
- 또한 FRR-FAR curve의 아래 면적을 **Integrated Error (IE)** 라고 하는데, ROC curve에서 AUROC 값이 클수록 좋은 것과 달리 이 값은 작을수록 좋은 성을 낸다고 판단한다.

